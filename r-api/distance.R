#' @param selected_models List of acceptable and nearly acceptable models generated by cluster_models()
#'
#' @title Retrieve training settings and other model information from database and bundled dataset
#' @description Fetches training settings subtree from Mongo and other model info currently from bundled model_data
#'
#' @import mongolite
#' @import jsonlite
#' @return List of dataframes with all information for acceptable and nearly acceptable models.
#' @export
#'
#' @examples retrieve_settings(list(
#' "acceptable_models"=list(...),
#' "nearly_acceptable_models"=list(...)))
retrieve_settings<-function(selected_models){
  verbose<-T

  # Refreshing connection to base_models
  con<-mongolite::mongo("base_models",
                        db="assistml",
                        url="mongodb://admin:admin@localhost:27017/")
  con$info()

  #  Refreshing connection to enriched models
  print("Connecting to mongo to get enriched models")
  enriched_models<-mongolite::mongo(collection = "enriched_models",
                                    db="assistml",
                                    url="mongodb://admin:admin@localhost:27017/")
  enriched_models$info()




 # Fields retrieved from model_data include
  # [1] "model.name"                "algo.fam"
  # [3] "dataset"                   "number.rows"
  # [5] "columns.change"            "first.data.type"
  # [7] "second.data.type"          "has.text.data"
  # [9] "numeric.ratio"             "categorical.ratio"
  # [11] "datetime.ratio"            "text.ratio"
  # [13] "categorical.text.encoding" "classification.type"
  # [15] "accuracy"                  "accuracy.label"
  # [17] "precision"                 "precision.label"
  # [19] "recall"                    "recall.label"
  # [21] "training.time"             "training.time.label"
  # [23] "sampling"                  "language"
  # [25] "test.size"                 "number.custom.params"
  # [27] "output"                    "performance.label"
  # [29] "performance.score"         "traintime.std"
  # [31] "performance.score.cont"

  # Fields that can be retrieved from enriched_models:
  # [1] "model_name"               "fam_name"
  # [3] "name"                     "rows"
  # [5] "columns_change"           "has_text_data"
  # [7] "numeric_ratio"            "categorical_ratio"
  # [9] "datetime_ratio"           "text_ratio"
  # [11] "training_time_std"        "performance_score"
  # [13] "performance_gap"          "categorical_encoding"
  # [15] "classification_type"      "error"
  # [17] "quantile_error"           "accuracy"
  # [19] "quantile_accuracy"        "precision"
  # [21] "quantile_precision"       "recall"
  # [23] "quantile_recall"          "training_time"
  # [25] "quantile_training_time"   "sampling"
  # [27] "language"                 "test_size"
  # [29] "nr_hyperparams"           "nr_hyperparams_label"
  # [31] "nr_of_features"           "nr_dependencies"
  # [33] "algorithm_implementation"

  #  Retrieve_Settings for ACCMODELS ####

  # Strings to query acceptable and nearly acceptable model from mongo
  # paste0("'{\"Model.Info.name\":{\"$in\":[\"",paste(selected_models$acceptable_models,collapse = "\", \""),"\"]}}'")

  #  Using the model_name values from the clustering done to retrive the training characteristics subtree fields from base_models in Mongo

  accmodel_settings<-con$find(query =eval(parse(text = paste0("'{\"Model.Info.name\":{\"$in\":[\"",paste(selected_models$acceptable_models,collapse = "\", \""),"\"]}}'"))),
                              fields = '{"Model.Training_Characteristics":true,"_id":false}')

  if(verbose){
    print(paste("Obtained from Mongo for ACC. Length should be a positive number:",length(accmodel_settings$Model$Training_Characteristics)))
  }



  accmodels_performance<-enriched_models$find(query =eval(parse(text = paste0("'{\"model_name\":{\"$in\":[\"",paste(selected_models$acceptable_models,collapse = "\", \""),"\"]}}'")))
                                              )
  # Taking all fields in enriched_models, except for those already used in previous phases. The vector indicates the position of fields NOT used
  accmodels_performance<-accmodels_performance[,-c(6,15,17)]

  #  OBSOLETE Using bundled model_data
  # accmodels_performance<-model_data[model_data$model.name %in% selected_models$acceptable_models,
  #                                   c(1,2,3,4,5,6,7,13,15,17,19,25,26,27,29,30,31)]

  # print(paste("From bundled dataset inside of retrieve_settings function before renaming:"))
  # print(paste(names(accmodels_performance), collapse = " AND "))

  # print(paste("Inside retrieve_settings function: From enriched_models in Mongo  before renaming:"))
  # print(names(accmodels_performance))

  # print("Adding to the accmodels_performance from Mongo:")
  # print(names(accmodel_settings$Model$Training_Characteristics[,!unlist(lapply(accmodel_settings$Model$Training_Characteristics, is.list))]))
  # print(" ")

  #  Adding data from base_models Training_Characteristics to complement what is in  enriched_models.
  accmodels_performance<-cbind(accmodels_performance,
                               #Adding the number of hyper params
                                     accmodel_settings$Model$Training_Characteristics$Hyper_Parameters$nr_hyperparams,
                               #Adding specific fiels of Training_Characteristics. Should be avoided and instead be integrated in the Python scripts building enriched_models
                                     accmodel_settings$Model$Training_Characteristics[, names(accmodel_settings$Model$Training_Characteristics) %in% c("cores","deployment","ghZ","implementation","language_version")])

  # print("Added from Training_Characteristics in base_models Mongo to accmodels_performance:")
  # print(names(accmodel_settings$Model$Training_Characteristics[, names(accmodel_settings$Model$Training_Characteristics) %in% c("cores","deployment","ghZ","implementation","language_version")  ]))
  # print(" ")

  # Changing names of field containing similar data
  names(accmodels_performance)[names(accmodels_performance) %in% "number.rows"]<-"rows"
  names(accmodels_performance)[names(accmodels_performance) %in% "test.size"]<-"test_size_label"
  names(accmodels_performance)[names(accmodels_performance) %in% "number.custom.params"]<-"nr_customparams_label"
  names(accmodels_performance)[names(accmodels_performance) %in% "accmodel_settings$Model$Training_Characteristics$Hyper_Parameters$nr_hyperparams"]<-"nr_hyperparamas"
  names(accmodels_performance)[names(accmodels_performance) %in% "No of Cross Validation Folds Used"]<-"cross_validation_folds"



  # If duplicate column "deployment" is found, remove it from the dataframe
  # if(!is.na(match("deployment", names(accmodels_performance)))){
  #   accmodels_performance<-accmodels_performance[,-(match("deployment", names(accmodels_performance)))]
  # }

  # print(paste("Inside retrieve_settings. Contents of accmodels_performance after renaming and combining:"))
  # print(names(accmodels_performance))
  # print(" ")

  #  Retrieve_Settings for NACCMODELS ####

  if(selected_models$nearly_acceptable_models[1] %in% c("none")){

    return(list("accmodels"=accmodels_performance))

  }else{
    # Strings to query acceptable and nearly acceptable model from mongo
    # paste0("'{\"Model.Info.name\":{\"$in\":[\"",paste(selected_models$nearly_acceptable_models,collapse = "\", \""),"\"]}}'")

    #  Using the model_name values from the clustering done to retrive the training characteristics subtree fields from base_models in Mongo
    naccmodel_settings<-con$find(query =eval(parse(text = paste0("'{\"Model.Info.name\":{\"$in\":[\"",paste(selected_models$nearly_acceptable_models,collapse = "\", \""),"\"]}}'"))),
                                 fields = '{"Model.Training_Characteristics":true,"_id":false}')

    if(verbose){
      print(paste("Obtained from Mongo for NACC. Length should be a positive number:",length(naccmodel_settings$Model$Training_Characteristics)))
    }

    naccmodels_performance<-enriched_models$find(query =eval(parse(text = paste0("'{\"model_name\":{\"$in\":[\"",paste(selected_models$nearly_acceptable_models,collapse = "\", \""),"\"]}}'")))
    )
    # Taking all fields in enriched_models, except for those already used in previous phases. The vector indicates the position of fields NOT used
    naccmodels_performance<-naccmodels_performance[,-c(6,15,17)]

    #  OBSOLETE Using bundled model_data
    # naccmodels_performance<-model_data[model_data$model.name %in% selected_models$nearly_acceptable_models,
    #                                    c(1,2,3,4,5,6,7,13,15,17,19,25,26,27,29,30,31)]

    naccmodels_performance<-cbind(naccmodels_performance,
                                  #Adding the number of hyper params
                                  naccmodel_settings$Model$Training_Characteristics$Hyper_Parameters$nr_hyperparams,
                                  # Adding specific fiels of Training_Characteristics. Should be avoided and instead be integrated in the Python scripts building enriched_models
                                  naccmodel_settings$Model$Training_Characteristics[, names(naccmodel_settings$Model$Training_Characteristics) %in% c("cores","deployment","ghZ","implementation","language_version")])

    # Changing names of field containing similar data
    names(naccmodels_performance)[names(naccmodels_performance) %in% "number.rows"]<-"nr_rows_segment"
    names(naccmodels_performance)[names(naccmodels_performance) %in% "test.size"]<-"test_size_label"
    names(naccmodels_performance)[names(naccmodels_performance) %in% "number.custom.params"]<-"nr_customparams_label"
    names(naccmodels_performance)[names(naccmodels_performance) %in% "naccmodel_settings$Model$Training_Characteristics$Hyper_Parameters$nr_hyperparams"]<-"nr_hyperparamas"
    names(naccmodels_performance)[names(naccmodels_performance) %in% "No of Cross Validation Folds Used"]<-"cross_validation_folds"

    # If duplicate column "deployment" is found, remove it from the dataframe
    # if(!is.na(match("deployment", names(naccmodels_performance)))){
    #   naccmodels_performance<-naccmodels_performance[,-(match("deployment", names(naccmodels_performance)))]
    # }

    # print(paste("Inside retrieve_settings. Contents of naccmodels_performance after renaming:"))
    # print(names(naccmodels_performance))
    # print(" ")


    return(list("accmodels"=accmodels_performance,
                "naccmodels"=naccmodels_performance))
  }



}





#' @param accmodels_performance Dataframe with acceptable models. Model name must be on first column.
#' @param query_df Dataframe with fields comparable to those in cluster to compute Hamming distance.
#' @param naccmodels_performance Dataframe with nearly acceptable models. Model name must be on first column.
#'
#' @title Compute Hamming distances for five different cases
#' @description Computes Hamming distances for five different cases.
#' Two for distances within the acceptable or nearly acceptable models,
#' two more between the query and either the acceptable or nearly acceptable models.
#' One for the distances between models in the border of acceptable and nearly acceptable models.
#'
#' @return Lists of computed Hamming \code{distances} to the issued query, between model groups and inside each model group
#' @export
#'
#' @examples compute_distances(dataframe_acceptable, dataframe_nearly_acceptable, dataframe_query)
compute_distances<-function(accmodels_performance,naccmodels_performance,query_df){
  elements_to_compare<-3 #Internal param to keep all comparisons manageable

  # print("Choosing from...")
  # print(names(accmodels_performance))
  # print("Choosing from...")
  # print(names(naccmodels_performance))
  # print(" ")

  # NEW FIELDS TO CHOOSE FROM, once data is pulled from Mongo
  # [1] "model_name"               "fam_name"                 "name"                     "rows"                     "columns_change"
  # [6] "numeric_ratio"            "categorical_ratio"        "datetime_ratio"           "text_ratio"               "training_time_std"
  # [11] "performance_score"        "performance_gap"          "categorical_encoding"     "error"                    "accuracy"
  # [16] "precision"                "recall"                   "sampling"                 "language"                 "test_size"
  # [21] "nr_hyperparams"           "nr_hyperparams_label"     "nr_of_features"           "nr_dependencies"          "algorithm_implementation"
  # [26] "nr_hyperparamas"          "language_version"         "cores"                    "ghZ"                      "deployment"
  # [31] "implementation"


    # OLD FIELDS TO BUILD THE COMPARISON VECTORS. AVAILABLE IN FOR BOTH ACC AND NACC MODELS
  # [1] "model_name"               "fam_name"                 "name"                     "rows"
  # [5] "columns_change"           "training_time_std"        "performance_score"        "performance_gap"
  # [9] "categorical_encoding"     "error"                    "accuracy"                 "precision"
  # [13] "recall"                   "sampling"                 "language"                 "test_size"
  # [17] "nr_hyperparams"           "nr_hyperparams_label"     "nr_of_features"           "nr_dependencies"
  # [21] "algorithm_implementation" "nr_hyperparams"           "language_version"         "cores"
  # [25] "ghZ"                      "deployment"               "implementation"

  comparison.intracluster<-c("model_name","fam_name","rows","columns_change","performance_gap","categorical_encoding","performance_score","quantile_accuracy","quantile_precision","quantile_recall","quantile_training_time","sampling","language","nr_of_features","nr_hyperparams","nr_hyperparamas","nr_dependencies","algorithm_implementation","deployment","implementation")

  comparison.interclusters<-c("model_name","fam_name","rows","columns_change","performance_gap","categorical_encoding","performance_score","quantile_accuracy","quantile_precision","quantile_recall","quantile_training_time","sampling","language","nr_of_features","nr_hyperparams","nr_hyperparamas","nr_dependencies","algorithm_implementation","deployment","implementation")

  comparison.query<-c("model_name","fam_name","rows","language","nr_hyperparams_label","deployment","implementation")

  ## TODO!: Add to comparison query and query df "quantile_accuracy","quantile_precision","quantile_recall","quantile_training_time",   ####



  # comparison.intracluster<-c(1,2,4,5,6,7,8,12,13,14,15,19,20,21,23,27) # Used with old fields 6 and 7 are the first and second data types 12 to 15 are the performance labels
  # comparison.interclusters<-c(1,2,4,5,6,7,8,12,13,14,15,19,20,21,23,27) # Used with old fields
  # comparison.query<-c(1,2,4,6,7,15,18,20,26,27)



  print(" ")
  # print("Fields to do comparison INSIDE ONE cluster")
  # print(names(accmodels_performance[,comparison.intracluster]))
  # print(" ")
  # print("Fields to do comparison BETWEEN TWO clusters")
  # print(names(accmodels_performance[,comparison.interclusters]))
  print(" ")
  # print("Fields to do comparison AGAINST a query")
  # print(names(accmodels_performance[,comparison.query]))


  print(" ")

  main_datatypes_acc<-data.frame("first_datatype","second_datatype",stringsAsFactors = F)
  names(main_datatypes_acc)<-c("first_datatype","second_datatype")

  data_types_acc<-accmodels_performance[,names(accmodels_performance) %in% c("model_name","numeric_ratio","categorical_ratio", "datetime_ratio", "text_ratio")]
  for (i in 1:nrow(data_types_acc)) {
    main_datatypes_acc<-rbind(main_datatypes_acc,names(sort(data_types_acc[i,2:5],decreasing = T)[1:2]))
  }
  main_datatypes_acc<-main_datatypes_acc[2:nrow(main_datatypes_acc),]

  # print(head(main_datatypes_acc))

  main_datatypes_nacc<-data.frame("first_datatype","second_datatype",stringsAsFactors = F)
  names(main_datatypes_nacc)<-c("first_datatype","second_datatype")

  data_types_nacc<-naccmodels_performance[,names(naccmodels_performance) %in% c("model_name","numeric_ratio","categorical_ratio", "datetime_ratio", "text_ratio")]

  for (j in 1:nrow(data_types_nacc)) {
    main_datatypes_nacc<-rbind(main_datatypes_nacc,names(sort(data_types_nacc[j,2:5],decreasing = T)[1:2]))
  }
  main_datatypes_nacc<-main_datatypes_nacc[2:nrow(main_datatypes_nacc),]

  # print(head(main_datatypes_nacc))



  print(paste0("Measuring distances inside regions with ",length(comparison.intracluster)-1," fields"))
  print(paste0("Measuring distances on the border between regions with ",length(comparison.interclusters)-1," fields"))
  print(paste0("Measuring distances to the query with ",length(comparison.query)-1," fields"))


# Intracluster comparisons
  print("Computing distances INSIDE of ACCmodels")
  distances_accmodels<-hamming_distance(cbind(accmodels_performance[,names(accmodels_performance) %in% comparison.intracluster],main_datatypes_acc),
                                        cbind(accmodels_performance[,names(accmodels_performance) %in% comparison.intracluster],main_datatypes_acc))

  print("Computing distances INSIDE of NACCmodels")
  distances_naccmodels<-hamming_distance(cbind(naccmodels_performance[,names(naccmodels_performance) %in% comparison.intracluster],main_datatypes_nacc),
                                         cbind(naccmodels_performance[,names(naccmodels_performance) %in% comparison.intracluster],main_datatypes_nacc))

  # Across clusters comparison
  # Worst performing from Acceptable in Accuracy
  # accmodels_performance[accmodels_performance[,15]
  #                       %in% sort(accmodels_performance[,15])[1:elements_to_compare],comparison.interclusters]

  # Best performing from Nearly Acceptable
  # naccmodels_performance[naccmodels_performance[,15]
  #                        %in% sort(naccmodels_performance[,15],decreasing = T)[1:elements_to_compare],comparison.interclusters]


  # print("accmodels_performance")
  # print(head(accmodels_performance))
  # print("naccmodels_performance")
  # print(head(naccmodels_performance))
  # print(" ")

  print(paste("Computing distances BETWEEN ACCmodels and NACCmodels with",elements_to_compare,"models from each group ranked by",names(accmodels_performance)[names(accmodels_performance) %in% "performance_score"])) # The performance_score
  print("")

  print(accmodels_performance[accmodels_performance[,names(accmodels_performance) %in% "performance_score"] %in% sort(accmodels_performance[,names(accmodels_performance) %in% "performance_score"])[1:elements_to_compare],names(accmodels_performance) %in% comparison.interclusters])
  print("")
  print(naccmodels_performance[naccmodels_performance[,names(naccmodels_performance) %in% "performance_score"] %in% sort(naccmodels_performance[,names(naccmodels_performance) %in% "performance_score"],decreasing = T)[1:elements_to_compare],names(naccmodels_performance) %in% comparison.interclusters])

  # Acceptable models in rows, Nearly acceptable ones in columns
  border_comparison<-hamming_distance(
    accmodels_performance[accmodels_performance[,names(accmodels_performance) %in% "performance_score"] %in% sort(accmodels_performance[,names(accmodels_performance) %in% "performance_score"])[1:elements_to_compare],names(accmodels_performance) %in% comparison.interclusters],
    naccmodels_performance[naccmodels_performance[,names(naccmodels_performance) %in% "performance_score"] %in% sort(naccmodels_performance[,names(naccmodels_performance) %in% "performance_score"],decreasing = T)[1:elements_to_compare],names(naccmodels_performance) %in% comparison.interclusters]
    )

  print(paste("Calling distance to query for ACCmodels:"))
  # print(paste(names(accmodels_performance)[comparison.query],collapse = " AND "))

  distance_queryacc<-hamming_distance(cbind(accmodels_performance[,names(accmodels_performance) %in% comparison.query],main_datatypes_acc),
                                      query_df)
  print(paste("Calling distance to query for NACCmodels:"))
  distance_querynacc<-hamming_distance(cbind(naccmodels_performance[,names(naccmodels_performance) %in% comparison.query],main_datatypes_nacc),
                                       query_df)




  # mean(apply(all.distances, 2, mean))
  # max(apply(all.distances, 2, max))
  # sort(apply(all.distances, 2, sum))

  distances<-list(
    "query_accmodels"=distance_queryacc,
    "query_naccmodels"=distance_querynacc,
    "between"=border_comparison,
    "accmodels"=distances_accmodels,
    "naccmodels"=distances_naccmodels,
    "scales"=list(
      "incluster"=length(comparison.intracluster)-1,
      "border"=length(comparison.interclusters)-1,
      "query"=length(comparison.query)-1
    )
  )

  return(distances)


  }




#' @param df1 dataframe with model names in first col, rest with comparison bits
#'
#' @param df2 dataframe with model names in first col, rest with comparison bits
#'
#' @title Computes Hamming distance between two supplied dataframes
#' @description Given two dataframes of equal length, it measures the hamming distance  between all their elements.
#' Generic method to measure all distances.
#'
#' @return Data frame with all distances. df1 is rows, df2 is columns.
#' @export
#'
#' @examples
hamming_distance<-function(df1,df2){
  # Hamming distance between clusters
  all.distances<-as.data.frame(matrix(1:nrow(df2), ncol = nrow(df2), nrow = 1))
  print(paste("In hamming_distance(). Data Frames contain:"))
  print("DF1")
  print(sort(names(df1)[-which(names(df1) %in% "model_name")]))
  print("DF2")
  print(sort(names(df2)[-which(names(df2) %in% "model_name")]))
  print(" ")

  for (i in 1:nrow(df1)) {
    single.distances<-c()
    for (j in 1:nrow(df2)) {
      one.distance<- -1
      if(!df1[i,1]==df2[j,1]){

        one.distance<-sum(df1[i,sort(names(df1)[-which(names(df1) %in% "model_name")])]
                          !=
                            df2[j,sort(names(df2)[-which(names(df2) %in% "model_name")])])


      }else{
        one.distance<-0
      }
      single.distances<-c(single.distances,one.distance)
    }

    all.distances<-rbind(all.distances,single.distances)
  }
  # Removing guide number trace. Casting as data frame in case it wants to be treated as named int
  all.distances<-as.data.frame(all.distances[2:nrow(all.distances),])

  names(all.distances)<-as.character(df2[,1])
  row.names(all.distances)<-as.character(df1[,1])
  # paste("model",1:ncol(all.distances))

  return(all.distances)
}


#' @title Details of hamming distance between query and a single model
#' @description Provides details about which fields are similar or different between two dataframes. Meant for the explanation of query details.
#'
#' @param df1 Dataframe describing a single model or a query.
#' @param df2 Dataframe describing a single model or a query.
#'
#' @return Array of strings with name of the field and TRUE if value is different from query.
#' @export
#'
#' @examples
hamming_details<-function(df1,df2){
  # Hamming distance between clusters

  # print(paste("Inside distance details query:"))
  # print(paste(sort(names(df1)[-which(names(df1) %in% "model_name")]),collapse = " AND "))
  # print(paste(sort(names(df2)[-which(names(df2) %in% "model_name")]),collapse = " AND "))

  # print(paste("Inside hamming_details query:"))
  # print(paste(class(df1),"DF1"))
  # print(df1)
  # print(sort(names(df1)[-which(names(df1) %in% "model_name")]))
  print(" ")

  # print(paste(class(df2),"DF2"))
  # print(df2)
  # print(sort(names(df2)[-which(names(df2) %in% "model_name")]))
  print(" ")
  # print(paste(sort(names(df1)[-which(names(df1) %in% "model_name")]),
  #             "!=",
  #             sort(names(df2)[-which(names(df2) %in% "model_name")])
  #             ))

        single.distances<-as.array(df1[1,sort(names(df1)[-which(names(df1) %in% "model_name")])]
                                   !=
                                     df2[1,sort(names(df2)[-which(names(df2) %in% "model_name")])])

        # print("single.distances")
        # print(single.distances)

        distance_details<-paste(sort(names(df2)[-which(names(df2) %in% "model_name")]),as.character(single.distances)) #Combines name of field and comparison value to produce the list of differences

        # print("distance_details")
        # print(distance_details)
          # print(paste(names(df2[,2:ncol(df2)]),as.character(single.distances[k])))

        # single.distances<-as.character(single.distances)
        # print(single.distances)
        # print(paste("Generated distance details for:",as.character(df1[1,1]),"vs",as.character(df2[1,1]))) # To check that details correspond to the model being reported
  return(distance_details)
}
